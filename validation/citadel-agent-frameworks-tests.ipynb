{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efd86dc",
   "metadata": {},
   "source": [
    "# ü§ñ Citadel Agent Frameworks Testing Center\n",
    "\n",
    "## Test Access Contracts with Different Agent Frameworks!\n",
    "\n",
    "This notebook tests the Citadel Access Contracts using different agent frameworks to simulate multi-turn conversations:\n",
    "\n",
    "| Access Contract | Agent Framework | Integration Type |\n",
    "|----------------|-----------------|------------------|\n",
    "| **Sales-Assistant** | Microsoft Agent Framework | Azure Key Vault (endpoint + key) |\n",
    "| **HR-ChatAgent** | Microsoft Foundry Agent SDK | Foundry Project Connection |\n",
    "| **Support-Bot** | LangChain | Local (direct endpoint + key) |\n",
    "\n",
    "Each agent will simulate a conversation with a user around the topic of its access contract title.\n",
    "\n",
    "> **Prerequisites:**\n",
    "> - Citadel Governance Hub deployed with access contracts\n",
    "> - Run `citadel-access-contracts-tests.ipynb` first to create the test contracts\n",
    "> - Python packages: `agent-framework`, `azure-ai-projects`, `langchain`, `langchain-openai` among others (see step )\n",
    "> - Have both Azure Key Vault and Foundry target resources provisioned and accessible (permissions and network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea31a224",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize Notebook Variables\n",
    "\n",
    "Configure the same environment variables used in the access contracts tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Allow nested asyncio event loops (required for Jupyter)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "sys.path.insert(1, '../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "from apimtools import APIMClientTool\n",
    "\n",
    "inference_api_version = \"2024-05-01-preview\"\n",
    "targetInferenceApi = \"models\"  # use 'models' for universal LLM API, or 'openai' for Azure OpenAI\n",
    "\n",
    "governance_hub_resource_group = \"rg-ai-hub-citadel-dev-34\"  ## specify the resource group name\n",
    "location = \"swedencentral\"  ## specify the location of the Governance Hub\n",
    "\n",
    "# Azure Key Vault configuration (for Sales-Assistant - Microsoft Agent Framework)\n",
    "keyvault_subscription_id = \"d2e7f84f-2790-4baa-9520-59ae8169ed0d\"\n",
    "keyvault_resource_group = \"rg-foundry-agent-spoke-01\"\n",
    "keyvault_name = \"kv-foundry-spoke-01\"\n",
    "\n",
    "# Azure AI Foundry configuration (for HR-ChatAgent - Foundry Agent SDK)\n",
    "use_foundry_integration = True\n",
    "foundry_subscription_id = \"d2e7f84f-2790-4baa-9520-59ae8169ed0d\"\n",
    "foundry_resource_group = \"rg-foundry-agent-spoke-01\"\n",
    "foundry_account_name = \"msf-foundry-agent-spoke-01\"\n",
    "foundry_project_name = \"crm-support-agent\"\n",
    "foundry_connection_name = \"HR-ChatAgent-DEV-LLM\"  # Connection created by access contract\n",
    "\n",
    "# Model configuration\n",
    "model_name = \"gpt-4o\"  # Model to use for agents\n",
    "\n",
    "# Retry configuration\n",
    "MAX_RETRIES = 3          # Maximum number of retries per call\n",
    "RETRY_DELAY_BASE = 2     # Base delay in seconds (exponential backoff: base * 2^attempt)\n",
    "\n",
    "# Store metrics for each agent (including retries)\n",
    "agent_metrics = {\n",
    "    \"MS Agent Framework (Sales)\": {\"total_tokens\": 0, \"prompt_tokens\": 0, \"completion_tokens\": 0, \"calls\": 0, \"retries\": 0},\n",
    "    \"Foundry SDK (HR)\": {\"total_tokens\": 0, \"prompt_tokens\": 0, \"completion_tokens\": 0, \"calls\": 0, \"retries\": 0},\n",
    "    \"LangChain (Support)\": {\"total_tokens\": 0, \"prompt_tokens\": 0, \"completion_tokens\": 0, \"calls\": 0, \"retries\": 0}\n",
    "}\n",
    "\n",
    "utils.print_ok(\"Notebook variables initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce85794",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify Azure CLI and Initialize APIM Client\n",
    "\n",
    "Connect to Azure and discover the deployed access contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07425bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    apimClientTool = APIMClientTool(governance_hub_resource_group)\n",
    "    apimClientTool.initialize()\n",
    "    apimClientTool.discover_api(targetInferenceApi)\n",
    "\n",
    "    apim_resource_gateway_url = str(apimClientTool.apim_resource_gateway_url)\n",
    "    azure_endpoint = str(apimClientTool.azure_endpoint)\n",
    "    \n",
    "    # Get supported models\n",
    "    supported_models = apimClientTool.get_policy_fragment_supported_models(\"set-backend-pools\")\n",
    "    utils.print_info(f\"Supported models: {supported_models}\")\n",
    "\n",
    "    if targetInferenceApi == \"openai\":\n",
    "        chat_completions_url = f\"{azure_endpoint}openai/deployments/{{model_name}}/chat/completions?api-version={inference_api_version}\"\n",
    "    else:\n",
    "        chat_completions_url = f\"{azure_endpoint}models/chat/completions?api-version={inference_api_version}\"\n",
    "    \n",
    "    utils.print_info(f\"Chat Completion Endpoint: {chat_completions_url}\")\n",
    "    utils.print_ok(f\"APIM Client initialized!\")\n",
    "except Exception as e:\n",
    "    utils.print_error(f\"Error initializing APIM Client: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f97b88",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Retrieve Access Contract API Keys\n",
    "\n",
    "Get the API keys for each access contract to test with different agent frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the access contracts to test (matching those from citadel-access-contracts-tests.ipynb)\n",
    "access_contract_configs = [\n",
    "    {\n",
    "        \"name\": \"Sales-Assistant\",\n",
    "        \"business_unit\": \"Sales\",\n",
    "        \"use_case_name\": \"Assistant\",\n",
    "        \"environment\": \"DEV\",\n",
    "        \"agent_framework\": \"Microsoft Agent Framework\",\n",
    "        \"endpoint_secret\": \"SALES-LLM-ENDPOINT\",  # Key Vault secret names from access contract\n",
    "        \"apikey_secret\": \"SALES-LLM-KEY\",\n",
    "        \"description\": \"Sales Assistant - Helps with sales inquiries, product information, and pricing\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"HR-ChatAgent\",\n",
    "        \"business_unit\": \"HR\",\n",
    "        \"use_case_name\": \"ChatAgent\",\n",
    "        \"environment\": \"DEV\",\n",
    "        \"agent_framework\": \"Foundry SDK\",\n",
    "        \"foundry_connection\": foundry_connection_name,  # Foundry connection created by access contract\n",
    "        \"description\": \"HR Chat Agent - Assists with HR policies, benefits, and employee questions\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Support-Bot\",\n",
    "        \"business_unit\": \"Support\",\n",
    "        \"use_case_name\": \"Bot\",\n",
    "        \"environment\": \"DEV\",\n",
    "        \"agent_framework\": \"LangChain\",\n",
    "        \"description\": \"Support Bot - Provides technical support and troubleshooting assistance\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Map contracts to their subscription keys\n",
    "contract_keys = {}\n",
    "\n",
    "for config in access_contract_configs:\n",
    "    product_id = f\"LLM-{config['business_unit']}-{config['use_case_name']}-{config['environment']}\"\n",
    "    subscription_name = f\"{product_id}-SUB-01\"\n",
    "    \n",
    "    for sub in apimClientTool.apim_subscriptions:\n",
    "        if subscription_name.lower() in sub.get('name', '').lower():\n",
    "            contract_keys[config['name']] = {\n",
    "                \"key\": sub.get('key'),\n",
    "                \"product_id\": product_id,\n",
    "                \"agent_framework\": config['agent_framework'],\n",
    "                \"description\": config['description'],\n",
    "                \"config\": config  # Store full config for later use\n",
    "            }\n",
    "            utils.print_ok(f\"Found key for {config['name']} ({config['agent_framework']})\")\n",
    "            break\n",
    "    else:\n",
    "        utils.print_warning(f\"No key found for {config['name']} - run citadel-access-contracts-tests.ipynb first\")\n",
    "\n",
    "utils.print_info(f\"\\nRetrieved keys for {len(contract_keys)} access contracts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57dac01",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Install Required Agent Frameworks\n",
    "\n",
    "Install the necessary Python packages for each agent framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013dc271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install agent framework packages\n",
    "packages = [\n",
    "    \"agent-framework\",                 # Microsoft Agent Framework\n",
    "    \"azure-ai-projects>=2.0.0b2\",     # Microsoft Foundry Agent SDK\n",
    "    \"langchain>=0.2.0\",               # LangChain\n",
    "    \"langchain-openai>=0.1.0\",        # LangChain OpenAI integration\n",
    "    \"azure-identity\",                  # Azure authentication\n",
    "    \"azure-keyvault-secrets\",          # Azure Key Vault for Sales-Assistant\n",
    "    \"nest-asyncio\",                    # For running async in Jupyter\n",
    "    \"pywin32\",                         # For Windows users to avoid event loop issues\n",
    "    \"matplotlib\"                       # For visualizations\n",
    "]\n",
    "\n",
    "utils.print_info(\"Installing agent framework packages...\")\n",
    "for package in packages:\n",
    "    try:\n",
    "        %pip install -q {package}\n",
    "        utils.print_ok(f\"Installed {package}\")\n",
    "    except Exception as e:\n",
    "        utils.print_warning(f\"Could not install {package}: {e}\")\n",
    "\n",
    "utils.print_ok(\"Package installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527925b5",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† Agent Framework Implementations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae6712f",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ Microsoft Agent Framework (Sales-Assistant)\n",
    "\n",
    "Create a Sales Assistant agent using **Microsoft Agent Framework**.\n",
    "This agent retrieves its endpoint and API key from **Azure Key Vault** based on the access contract parameters.\n",
    "\n",
    "> **Key Vault Secrets:**\n",
    "> - `SALES-LLM-ENDPOINT`: The LLM endpoint URL\n",
    "> - `SALES-LLM-KEY`: The API key for authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from datetime import datetime\n",
    "\n",
    "class MSAgentFrameworkSalesAgent:\n",
    "    \"\"\"Sales Assistant Agent using Microsoft Agent Framework with Azure Key Vault integration.\n",
    "    \n",
    "    Uses ChatAgent with OpenAIChatClient configured with custom headers to work with \n",
    "    Azure API Management gateways that expect the 'api-key' header.\n",
    "    \n",
    "    Note: We use OpenAIChatClient (not AzureOpenAIChatClient) because:\n",
    "    - OpenAIChatClient uses standard OpenAI URL pattern: {base_url}/chat/completions\n",
    "    - AzureOpenAIChatClient uses Azure-specific pattern: {endpoint}/openai/deployments/{deployment}/...\n",
    "    - APIM gateways typically expect the standard OpenAI pattern with api-key header\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, keyvault_name: str, endpoint_secret_name: str, apikey_secret_name: str, model_name: str):\n",
    "        self.keyvault_name = keyvault_name\n",
    "        self.endpoint_secret_name = endpoint_secret_name\n",
    "        self.apikey_secret_name = apikey_secret_name\n",
    "        self.model_name = model_name\n",
    "        self.conversation_history = []\n",
    "        self.total_tokens = 0\n",
    "        self.prompt_tokens = 0\n",
    "        self.completion_tokens = 0\n",
    "        self.calls = 0\n",
    "        self.retries = 0\n",
    "        self.agent = None\n",
    "        self.thread = None  # AgentThread for conversation context\n",
    "        \n",
    "        # Retrieve endpoint and API key from Azure Key Vault\n",
    "        self._init_from_keyvault()\n",
    "        \n",
    "        # System prompt for Sales Assistant\n",
    "        self.system_prompt = f\"\"\"You are a Sales Assistant AI agent. Your role is to:\n",
    "- Answer questions about products and services\n",
    "- Provide pricing information and discounts\n",
    "- Help customers find the right solutions for their needs\n",
    "- Handle sales inquiries professionally and helpfully\n",
    "\n",
    "Be concise, professional, and always try to guide customers toward a purchase decision.\n",
    "Current date: {datetime.now().strftime(\"%Y-%m-%d\")}\"\"\"\n",
    "        \n",
    "        # Initialize Microsoft Agent Framework agent\n",
    "        self._init_agent()\n",
    "    \n",
    "    def _init_from_keyvault(self):\n",
    "        \"\"\"Retrieve endpoint and API key from Azure Key Vault.\"\"\"\n",
    "        try:\n",
    "            credential = DefaultAzureCredential()\n",
    "            keyvault_uri = f\"https://{self.keyvault_name}.vault.azure.net\"\n",
    "            client = SecretClient(vault_url=keyvault_uri, credential=credential)\n",
    "            \n",
    "            # Get endpoint from Key Vault\n",
    "            endpoint_secret = client.get_secret(self.endpoint_secret_name)\n",
    "            self.endpoint = endpoint_secret.value\n",
    "            utils.print_ok(f\"Retrieved endpoint: ({self.endpoint}) from Key Vault secret: {self.endpoint_secret_name}\")\n",
    "            \n",
    "            # Get API key from Key Vault\n",
    "            apikey_secret = client.get_secret(self.apikey_secret_name)\n",
    "            self.api_key = apikey_secret.value\n",
    "            utils.print_ok(f\"Retrieved API key ({self.api_key[:4]}****) from Key Vault secret: {self.apikey_secret_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            utils.print_error(f\"Failed to retrieve secrets from Key Vault: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _init_agent(self):\n",
    "        \"\"\"Initialize the Microsoft Agent Framework agent using ChatAgent with OpenAIChatClient.\n",
    "        \n",
    "        Uses OpenAIChatClient with custom default_headers to send 'api-key' header\n",
    "        that Azure API Management expects, while using standard OpenAI URL patterns.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from agent_framework import ChatAgent\n",
    "            from agent_framework.openai import OpenAIChatClient\n",
    "            \n",
    "            # Create OpenAI Chat Client with custom headers for APIM authentication\n",
    "            # OpenAIChatClient uses standard /chat/completions URL pattern (what APIM expects)\n",
    "            # We pass api-key via default_headers since APIM requires this header\n",
    "            chat_client = OpenAIChatClient(\n",
    "                base_url=self.endpoint,      # APIM endpoint from Key Vault (e.g., https://apim.../models)\n",
    "                api_key=\"placeholder\",       # Required but we override with default_headers\n",
    "                model_id=self.model_name,    # Model name\n",
    "                default_headers={\n",
    "                    \"api-key\": self.api_key  # APIM subscription key as api-key header\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Create ChatAgent using Microsoft Agent Framework\n",
    "            self.agent = ChatAgent(\n",
    "                chat_client=chat_client,\n",
    "                name=\"SalesAssistant\",\n",
    "                instructions=self.system_prompt,\n",
    "            )\n",
    "            \n",
    "            # Create a conversation thread for multi-turn conversations\n",
    "            self.thread = self.agent.get_new_thread()\n",
    "            \n",
    "            utils.print_ok(\"Microsoft Agent Framework ChatAgent initialized successfully (using OpenAIChatClient with api-key header)\")\n",
    "            \n",
    "        except ImportError as e:\n",
    "            error_msg = (\n",
    "                f\"‚ùå Failed to import Microsoft Agent Framework: {e}\\n\"\n",
    "                \"  ‚Üí Fix: Install the package with: pip install agent-framework\\n\"\n",
    "                \"  ‚Üí Ensure you have the correct version installed\"\n",
    "            )\n",
    "            utils.print_error(error_msg)\n",
    "            raise RuntimeError(error_msg) from e\n",
    "        except Exception as e:\n",
    "            error_msg = (\n",
    "                f\"‚ùå Failed to initialize Microsoft Agent Framework ChatAgent: {e}\\n\"\n",
    "                \"  ‚Üí Verify the endpoint from Key Vault is correct and accessible\\n\"\n",
    "                \"  ‚Üí Verify the API key from Key Vault is valid\\n\"\n",
    "                \"  ‚Üí Check that the APIM gateway is running and the subscription is active\\n\"\n",
    "                f\"  ‚Üí Endpoint: {self.endpoint}\\n\"\n",
    "                f\"  ‚Üí Model: {self.model_name}\"\n",
    "            )\n",
    "            utils.print_error(error_msg)\n",
    "            raise RuntimeError(error_msg) from e\n",
    "    \n",
    "    async def chat_async(self, user_message: str) -> str:\n",
    "        \"\"\"Send a message and get a response using Microsoft Agent Framework with retry logic.\"\"\"\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        last_error = None\n",
    "        for attempt in range(MAX_RETRIES + 1):\n",
    "            try:\n",
    "                # Use Microsoft Agent Framework with thread for conversation context\n",
    "                result = await self.agent.run(user_message, thread=self.thread)\n",
    "                content = result.text if hasattr(result, 'text') else str(result)\n",
    "                \n",
    "                # Track metrics (Microsoft Agent Framework may not expose token counts directly)\n",
    "                # Estimate tokens based on response length\n",
    "                estimated_tokens = len(content.split()) * 1.3  # rough estimate\n",
    "                self.completion_tokens += int(estimated_tokens)\n",
    "                self.prompt_tokens += len(user_message.split())\n",
    "                self.total_tokens = self.prompt_tokens + self.completion_tokens\n",
    "                self.calls += 1\n",
    "                \n",
    "                if attempt > 0:\n",
    "                    utils.print_info(f\"  ‚úÖ Succeeded after {attempt} retry(ies)\")\n",
    "                \n",
    "                self.conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                return content\n",
    "                \n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    self.retries += 1\n",
    "                    delay = RETRY_DELAY_BASE * (2 ** attempt)\n",
    "                    utils.print_warning(f\"  ‚ö†Ô∏è Attempt {attempt + 1}/{MAX_RETRIES + 1} failed: {e}\")\n",
    "                    utils.print_info(f\"  ‚è≥ Retrying in {delay}s...\")\n",
    "                    await asyncio.sleep(delay)\n",
    "                else:\n",
    "                    # All retries exhausted ‚Äî report clear failure\n",
    "                    error_msg = (\n",
    "                        f\"‚ùå Microsoft Agent Framework call failed after {MAX_RETRIES + 1} attempts.\\n\"\n",
    "                        f\"  Last error: {last_error}\\n\"\n",
    "                        f\"  ‚Üí Check that the APIM gateway is healthy and not throttling requests\\n\"\n",
    "                        f\"  ‚Üí Verify the Sales-Assistant access contract rate limits\\n\"\n",
    "                        f\"  ‚Üí Ensure the model '{self.model_name}' is available in the backend pool\\n\"\n",
    "                        f\"  ‚Üí Endpoint: {self.endpoint}\"\n",
    "                    )\n",
    "                    utils.print_error(error_msg)\n",
    "                    self.conversation_history.append({\"role\": \"assistant\", \"content\": f\"[ERROR] {error_msg}\"})\n",
    "                    return f\"[ERROR] {error_msg}\"\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"Synchronous wrapper for chat_async.\"\"\"\n",
    "        return asyncio.get_event_loop().run_until_complete(self.chat_async(user_message))\n",
    "    \n",
    "    def get_metrics(self) -> dict:\n",
    "        \"\"\"Return token usage metrics including retries.\"\"\"\n",
    "        return {\n",
    "            \"total_tokens\": self.total_tokens,\n",
    "            \"prompt_tokens\": self.prompt_tokens,\n",
    "            \"completion_tokens\": self.completion_tokens,\n",
    "            \"calls\": self.calls,\n",
    "            \"retries\": self.retries\n",
    "        }\n",
    "\n",
    "utils.print_ok(\"Microsoft Agent Framework Sales Agent class defined (using OpenAIChatClient with api-key header)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Microsoft Agent Framework Sales Agent with Key Vault integration\n",
    "if \"Sales-Assistant\" in contract_keys:\n",
    "    config = contract_keys[\"Sales-Assistant\"][\"config\"]\n",
    "    \n",
    "    utils.print_info(\"ü§ñ Starting Microsoft Agent Framework Sales Agent conversation...\")\n",
    "    utils.print_info(\"=\"*60)\n",
    "    utils.print_info(f\"üì¶ Retrieving credentials from Azure Key Vault: {keyvault_name}\")\n",
    "    \n",
    "    try:\n",
    "        sales_agent = MSAgentFrameworkSalesAgent(\n",
    "            keyvault_name=keyvault_name,\n",
    "            endpoint_secret_name=config.get(\"endpoint_secret\", \"SALES-LLM-ENDPOINT\"),\n",
    "            apikey_secret_name=config.get(\"apikey_secret\", \"SALES-LLM-KEY\"),\n",
    "            model_name=model_name\n",
    "        )\n",
    "        \n",
    "        # Simulate a sales conversation\n",
    "        sales_conversation = [\n",
    "            \"Hi, I'm looking for an enterprise AI solution for my company.\",\n",
    "            \"What features do you offer for data analytics?\",\n",
    "            \"How much does the enterprise plan cost?\",\n",
    "            \"Do you offer any discounts for annual subscriptions?\",\n",
    "            \"Can you help me set up a demo?\"\n",
    "        ]\n",
    "        \n",
    "        for i, user_msg in enumerate(sales_conversation, 1):\n",
    "            print(f\"\\nüë§ User ({i}/{len(sales_conversation)}): {user_msg}\")\n",
    "            response = sales_agent.chat(user_msg)\n",
    "            print(f\"ü§ñ Sales Agent: {response[:300]}{'...' if len(response) > 300 else ''}\")\n",
    "            time.sleep(1)  # Rate limiting\n",
    "        \n",
    "        # Store metrics\n",
    "        agent_metrics[\"MS Agent Framework (Sales)\"] = sales_agent.get_metrics()\n",
    "        utils.print_ok(f\"\\nüìä Sales Agent Metrics: {agent_metrics['MS Agent Framework (Sales)']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        utils.print_error(f\"Failed to initialize Sales Agent: {e}\")\n",
    "        utils.print_info(\"Make sure Key Vault secrets are configured and you have access permissions.\")\n",
    "else:\n",
    "    utils.print_warning(\"Sales-Assistant contract not found. Skipping Microsoft Agent Framework test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f97a9b",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### 5Ô∏è‚É£ Microsoft Foundry Agent SDK (HR-ChatAgent)\n",
    "\n",
    "Create an HR Chat Agent using the **Microsoft Foundry Agent SDK** with the official **Prompt Agent** pattern.\n",
    "\n",
    "> **Foundry Integration (based on official sample):**\n",
    "> - Uses `PromptAgentDefinition` to create a versioned agent\n",
    "> - Uses `conversations` API for multi-turn dialogue\n",
    "> - Uses `responses` API to get agent responses\n",
    "> - Deployment pattern: `connection_name/model_name` routes through Citadel\n",
    "> - Authenticates using Azure DefaultAzureCredential\n",
    ">\n",
    "> **Reference:** [sample_agent_basic.py](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/agents/sample_agent_basic.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4305b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from datetime import datetime\n",
    "\n",
    "class FoundryHRAgent:\n",
    "    \"\"\"HR Chat Agent using Microsoft Foundry Agent SDK with Prompt Agent pattern.\n",
    "    \n",
    "    Uses the Azure AI Projects SDK following the official sample pattern:\n",
    "    - Creates a versioned Prompt Agent using PromptAgentDefinition\n",
    "    - Uses conversations API for multi-turn dialogue\n",
    "    - Uses responses API for agent responses\n",
    "    - Uses get_openai_client() as context manager per the official SDK pattern\n",
    "    \n",
    "    Based on: https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/agents/sample_agent_basic.py\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, foundry_account_name: str, foundry_project_name: str, \n",
    "                 connection_name: str, model_name: str):\n",
    "        self.foundry_account_name = foundry_account_name\n",
    "        self.foundry_project_name = foundry_project_name\n",
    "        self.connection_name = connection_name\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Deployment name pattern: connection_name/model_name\n",
    "        # This routes through the Foundry connection to Citadel governance hub\n",
    "        self.deployment_name = f\"{connection_name}/{model_name}\"\n",
    "        \n",
    "        # Metrics tracking\n",
    "        self.total_tokens = 0\n",
    "        self.prompt_tokens = 0\n",
    "        self.completion_tokens = 0\n",
    "        self.calls = 0\n",
    "        self.retries = 0\n",
    "        \n",
    "        # SDK clients and agent references\n",
    "        self.credential = None\n",
    "        self.project_client = None\n",
    "        self.agent = None\n",
    "        self.conversation_id = None  # Track conversation ID for multi-turn\n",
    "        \n",
    "        # System prompt for HR Assistant\n",
    "        self.system_prompt = f\"\"\"You are an HR Chat Agent AI assistant. Your role is to:\n",
    "- Answer questions about company HR policies\n",
    "- Explain employee benefits and compensation packages\n",
    "- Help with onboarding and offboarding procedures\n",
    "- Provide guidance on workplace conduct and compliance\n",
    "- Assist with leave requests and time-off policies\n",
    "\n",
    "Be empathetic, professional, and ensure you protect employee privacy.\n",
    "Always recommend consulting with HR directly for sensitive matters.\n",
    "Current date: {datetime.now().strftime(\"%Y-%m-%d\")}\"\"\"\n",
    "        \n",
    "        # Initialize Foundry client and create agent\n",
    "        self._init_foundry_client()\n",
    "    \n",
    "    def _init_foundry_client(self):\n",
    "        \"\"\"Initialize Azure AI Foundry project client and create Prompt Agent.\"\"\"\n",
    "        try:\n",
    "            from azure.ai.projects import AIProjectClient\n",
    "            from azure.ai.projects.models import PromptAgentDefinition\n",
    "            \n",
    "            # Build the endpoint for the Foundry project\n",
    "            # Format: https://{account}.services.ai.azure.com/api/projects/{project}\n",
    "            endpoint = f\"https://{self.foundry_account_name}.services.ai.azure.com/api/projects/{self.foundry_project_name}\"\n",
    "            \n",
    "            utils.print_info(f\"Connecting to Foundry endpoint: {endpoint}\")\n",
    "            \n",
    "            # Create credential and project client\n",
    "            self.credential = DefaultAzureCredential()\n",
    "            self.project_client = AIProjectClient(\n",
    "                endpoint=endpoint,\n",
    "                credential=self.credential\n",
    "            )\n",
    "            utils.print_ok(f\"Foundry project client initialized for: {self.foundry_project_name}\")\n",
    "            \n",
    "            # Create a versioned Prompt Agent using the official pattern\n",
    "            self.agent = self.project_client.agents.create_version(\n",
    "                agent_name=\"HR-ChatAgent\",\n",
    "                definition=PromptAgentDefinition(\n",
    "                    model=self.deployment_name,  # connection_name/model_name routes through Citadel\n",
    "                    instructions=self.system_prompt,\n",
    "                ),\n",
    "            )\n",
    "            utils.print_ok(f\"Agent created (id: {self.agent.id}, name: {self.agent.name}, version: {self.agent.version})\")\n",
    "            utils.print_info(f\"Using deployment: {self.deployment_name}\")\n",
    "            \n",
    "        except ImportError as e:\n",
    "            error_msg = (\n",
    "                f\"‚ùå Import error - SDK version may not support Agents API: {e}\\n\"\n",
    "                \"  ‚Üí Fix: Install the correct SDK version with: pip install azure-ai-projects>=2.0.0b2\\n\"\n",
    "                \"  ‚Üí Ensure azure-ai-projects package is installed and up to date\"\n",
    "            )\n",
    "            utils.print_error(error_msg)\n",
    "            raise RuntimeError(error_msg) from e\n",
    "        except Exception as e:\n",
    "            error_msg = (\n",
    "                f\"‚ùå Failed to initialize Foundry agent: {e}\\n\"\n",
    "                f\"  ‚Üí Verify the Foundry account name: {self.foundry_account_name}\\n\"\n",
    "                f\"  ‚Üí Verify the Foundry project name: {self.foundry_project_name}\\n\"\n",
    "                f\"  ‚Üí Ensure the Foundry connection '{self.connection_name}' was created by the access contract\\n\"\n",
    "                f\"  ‚Üí Check that DefaultAzureCredential has access to the Foundry project\\n\"\n",
    "                f\"  ‚Üí Run 'az login' and ensure the correct subscription is selected\"\n",
    "            )\n",
    "            utils.print_error(error_msg)\n",
    "            raise RuntimeError(error_msg) from e\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"Send a message and get a response using Foundry Agents SDK with retry logic.\n",
    "        \n",
    "        Uses the conversations and responses API pattern from the official sample.\n",
    "        Uses get_openai_client() as a context manager per the SDK pattern.\n",
    "        \"\"\"\n",
    "        last_error = None\n",
    "        for attempt in range(MAX_RETRIES + 1):\n",
    "            try:\n",
    "                return self._chat_with_agent(user_message)\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    self.retries += 1\n",
    "                    delay = RETRY_DELAY_BASE * (2 ** attempt)\n",
    "                    utils.print_warning(f\"  ‚ö†Ô∏è Attempt {attempt + 1}/{MAX_RETRIES + 1} failed: {e}\")\n",
    "                    utils.print_info(f\"  ‚è≥ Retrying in {delay}s...\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    error_msg = (\n",
    "                        f\"‚ùå Foundry Agent call failed after {MAX_RETRIES + 1} attempts.\\n\"\n",
    "                        f\"  Last error: {last_error}\\n\"\n",
    "                        f\"  ‚Üí Check that the Foundry project '{self.foundry_project_name}' is accessible\\n\"\n",
    "                        f\"  ‚Üí Verify the connection '{self.connection_name}' routes correctly to Citadel\\n\"\n",
    "                        f\"  ‚Üí Ensure the model '{self.model_name}' is available via the connection\\n\"\n",
    "                        f\"  ‚Üí Check the HR-ChatAgent access contract rate limits and quotas\\n\"\n",
    "                        f\"  ‚Üí Deployment: {self.deployment_name}\"\n",
    "                    )\n",
    "                    utils.print_error(error_msg)\n",
    "                    return f\"[ERROR] {error_msg}\"\n",
    "    \n",
    "    def _chat_with_agent(self, user_message: str) -> str:\n",
    "        \"\"\"Chat using the Prompt Agent with conversations and responses API.\n",
    "        \n",
    "        Uses get_openai_client() as context manager, matching the official SDK pattern\n",
    "        from hr-chatagent-foundry-test notebook.\n",
    "        \"\"\"\n",
    "        with self.project_client.get_openai_client() as openai_client:\n",
    "            if self.conversation_id is None:\n",
    "                # Create a new conversation with the first user message\n",
    "                conversation = openai_client.conversations.create(\n",
    "                    items=[{\"type\": \"message\", \"role\": \"user\", \"content\": user_message}],\n",
    "                )\n",
    "                self.conversation_id = conversation.id\n",
    "                utils.print_info(f\"Created conversation (id: {self.conversation_id})\")\n",
    "            else:\n",
    "                # Add user message to existing conversation\n",
    "                openai_client.conversations.items.create(\n",
    "                    conversation_id=self.conversation_id,\n",
    "                    items=[{\"type\": \"message\", \"role\": \"user\", \"content\": user_message}],\n",
    "                )\n",
    "            \n",
    "            # Get response from the agent\n",
    "            response = openai_client.responses.create(\n",
    "                conversation=self.conversation_id,\n",
    "                extra_body={\"agent\": {\"name\": self.agent.name, \"type\": \"agent_reference\"}},\n",
    "                input=\"\",\n",
    "            )\n",
    "            \n",
    "            content = response.output_text if hasattr(response, 'output_text') else str(response)\n",
    "            \n",
    "            # Track metrics - estimate tokens since responses API may not return usage\n",
    "            estimated_prompt_tokens = len(user_message.split())\n",
    "            estimated_completion_tokens = int(len(content.split()) * 1.3)\n",
    "            self.prompt_tokens += estimated_prompt_tokens\n",
    "            self.completion_tokens += estimated_completion_tokens\n",
    "            self.total_tokens = self.prompt_tokens + self.completion_tokens\n",
    "            self.calls += 1\n",
    "            \n",
    "            return content\n",
    "    \n",
    "    def get_metrics(self) -> dict:\n",
    "        \"\"\"Return token usage metrics including retries.\"\"\"\n",
    "        return {\n",
    "            \"total_tokens\": self.total_tokens,\n",
    "            \"prompt_tokens\": self.prompt_tokens,\n",
    "            \"completion_tokens\": self.completion_tokens,\n",
    "            \"calls\": self.calls,\n",
    "            \"retries\": self.retries\n",
    "        }\n",
    "    \n",
    "    def close(self, delete_version: bool = False):\n",
    "        \"\"\"Clean up resources.\n",
    "        \n",
    "        Args:\n",
    "            delete_version: If True, deletes the agent version from Foundry. Default is False.\n",
    "        \"\"\"\n",
    "        if delete_version:\n",
    "            try:\n",
    "                if self.agent and self.project_client:\n",
    "                    self.project_client.agents.delete_version(\n",
    "                        agent_name=self.agent.name,\n",
    "                        agent_version=self.agent.version\n",
    "                    )\n",
    "                    utils.print_ok(f\"Agent version deleted (name: {self.agent.name}, version: {self.agent.version})\")\n",
    "            except Exception as e:\n",
    "                utils.print_warning(f\"Failed to delete agent version: {e}\")\n",
    "        else:\n",
    "            if self.agent:\n",
    "                utils.print_info(f\"Agent version retained (name: {self.agent.name}, version: {self.agent.version}). Pass delete_version=True to remove it.\")\n",
    "\n",
    "utils.print_ok(\"Foundry HR Agent class defined (using Prompt Agent with conversations/responses API)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f936a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Foundry SDK HR Agent with project connection\n",
    "if \"HR-ChatAgent\" in contract_keys:\n",
    "    config = contract_keys[\"HR-ChatAgent\"][\"config\"]\n",
    "    \n",
    "    utils.print_info(\"üè¢ Starting Microsoft Foundry SDK HR Agent conversation...\")\n",
    "    utils.print_info(\"=\"*60)\n",
    "    utils.print_info(f\"üì¶ Connecting to Foundry project: {foundry_project_name}\")\n",
    "    utils.print_info(f\"üîó Using connection: {config.get('foundry_connection', foundry_connection_name)}\")\n",
    "    \n",
    "    try:\n",
    "        hr_agent = FoundryHRAgent(\n",
    "            foundry_account_name=foundry_account_name,\n",
    "            foundry_project_name=foundry_project_name,\n",
    "            connection_name=config.get(\"foundry_connection\", foundry_connection_name),\n",
    "            model_name=model_name\n",
    "        )\n",
    "        \n",
    "        # Simulate an HR conversation\n",
    "        hr_conversation = [\n",
    "            \"Hello, I'm a new employee. Can you tell me about the benefits package?\",\n",
    "            \"What is the vacation policy? How many days do I get?\",\n",
    "            \"How do I request time off for a medical appointment?\",\n",
    "            \"What's the process for reporting workplace issues?\",\n",
    "            \"Thank you for your help! One more question - when is the next open enrollment period?\"\n",
    "        ]\n",
    "        \n",
    "        for i, user_msg in enumerate(hr_conversation, 1):\n",
    "            print(f\"\\nüë§ User ({i}/{len(hr_conversation)}): {user_msg}\")\n",
    "            response = hr_agent.chat(user_msg)\n",
    "            print(f\"ü§ñ HR Agent: {response[:300]}{'...' if len(response) > 300 else ''}\")\n",
    "            time.sleep(1)  # Rate limiting\n",
    "        \n",
    "        # Store metrics\n",
    "        agent_metrics[\"Foundry SDK (HR)\"] = hr_agent.get_metrics()\n",
    "        utils.print_ok(f\"\\nüìä HR Agent Metrics: {agent_metrics['Foundry SDK (HR)']}\")\n",
    "        \n",
    "        # Clean up (set delete_version=True to remove the agent version from Foundry)\n",
    "        hr_agent.close(delete_version=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        utils.print_error(f\"Failed to initialize HR Agent: {e}\")\n",
    "        utils.print_info(\"Make sure the Foundry connection is created by the access contract deployment.\")\n",
    "else:\n",
    "    utils.print_warning(\"HR-ChatAgent contract not found. Skipping Foundry SDK test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324b7be",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "### 6Ô∏è‚É£ LangChain Agent (Support-Bot)\n",
    "\n",
    "Create a Support Bot agent using the **LangChain** framework.\n",
    "This is a local agent that uses variables for the LLM endpoint, key, and model name.\n",
    "\n",
    "> **Local Configuration:**\n",
    "> - Endpoint: Retrieved from APIM client\n",
    "> - API Key: Retrieved from APIM subscription\n",
    "> - Model: Specified in request body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class LangChainSupportAgent:\n",
    "    \"\"\"Support Bot Agent using LangChain framework with local configuration.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_endpoint: str, api_key: str, model_name: str):\n",
    "        \"\"\"\n",
    "        Initialize LangChain Support Agent with direct endpoint configuration.\n",
    "        \n",
    "        Args:\n",
    "            llm_endpoint: The LLM API endpoint URL\n",
    "            api_key: The API key for authentication\n",
    "            model_name: The model name to include in request body\n",
    "        \"\"\"\n",
    "        self.llm_endpoint = llm_endpoint\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        self.messages = []\n",
    "        self.total_tokens = 0\n",
    "        self.prompt_tokens = 0\n",
    "        self.completion_tokens = 0\n",
    "        self.calls = 0\n",
    "        self.retries = 0\n",
    "        \n",
    "        # System prompt for Support Bot\n",
    "        self.system_prompt = f\"\"\"You are a Technical Support Bot AI assistant. Your role is to:\n",
    "- Help users troubleshoot technical issues\n",
    "- Provide step-by-step guidance for common problems\n",
    "- Explain technical concepts in simple terms\n",
    "- Escalate complex issues to human support when needed\n",
    "- Log and track support tickets\n",
    "\n",
    "Be patient, thorough, and always verify that the user's issue is resolved.\n",
    "Ask clarifying questions when needed to diagnose problems accurately.\n",
    "Current date: {datetime.now().strftime(\"%Y-%m-%d\")}\"\"\"\n",
    "        \n",
    "        self.messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n",
    "        \n",
    "        utils.print_ok(f\"LangChain Support Agent initialized\")\n",
    "        utils.print_info(f\"Endpoint: {self.llm_endpoint}\")\n",
    "        utils.print_info(f\"Model: {self.model_name}\")\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"\n",
    "        Send a message and get a response using LangChain patterns with retry logic.\n",
    "        Uses direct API calls with endpoint, key, and model in body.\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        # LangChain-style payload with model in body\n",
    "        payload = {\n",
    "            \"model\": self.model_name,  # Model name in body as per LangChain pattern\n",
    "            \"messages\": self.messages,\n",
    "            \"max_tokens\": 500,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        last_error = None\n",
    "        for attempt in range(MAX_RETRIES + 1):\n",
    "            try:\n",
    "                # Direct API call using configured endpoint and key\n",
    "                response = requests.post(\n",
    "                    self.llm_endpoint,\n",
    "                    headers={\n",
    "                        \"api-key\": self.api_key,\n",
    "                        \"Content-Type\": \"application/json\"\n",
    "                    },\n",
    "                    json=payload,\n",
    "                    timeout=60\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    content = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "                    \n",
    "                    # Track token usage\n",
    "                    usage = data.get(\"usage\", {})\n",
    "                    self.total_tokens += usage.get(\"total_tokens\", 0)\n",
    "                    self.prompt_tokens += usage.get(\"prompt_tokens\", 0)\n",
    "                    self.completion_tokens += usage.get(\"completion_tokens\", 0)\n",
    "                    self.calls += 1\n",
    "                    \n",
    "                    if attempt > 0:\n",
    "                        utils.print_info(f\"  ‚úÖ Succeeded after {attempt} retry(ies)\")\n",
    "                    \n",
    "                    self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "                    return content\n",
    "                elif response.status_code == 429:\n",
    "                    # Rate limited ‚Äî retry with backoff\n",
    "                    retry_after = int(response.headers.get(\"Retry-After\", RETRY_DELAY_BASE * (2 ** attempt)))\n",
    "                    raise Exception(f\"Rate limited (429). Retry-After: {retry_after}s. Body: {response.text[:200]}\")\n",
    "                else:\n",
    "                    raise Exception(f\"HTTP {response.status_code}: {response.text[:200]}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    self.retries += 1\n",
    "                    delay = RETRY_DELAY_BASE * (2 ** attempt)\n",
    "                    utils.print_warning(f\"  ‚ö†Ô∏è Attempt {attempt + 1}/{MAX_RETRIES + 1} failed: {e}\")\n",
    "                    utils.print_info(f\"  ‚è≥ Retrying in {delay}s...\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    error_msg = (\n",
    "                        f\"‚ùå LangChain Support Agent call failed after {MAX_RETRIES + 1} attempts.\\n\"\n",
    "                        f\"  Last error: {last_error}\\n\"\n",
    "                        f\"  ‚Üí Check that the APIM gateway is healthy and not throttling\\n\"\n",
    "                        f\"  ‚Üí Verify the Support-Bot access contract rate limits and quotas\\n\"\n",
    "                        f\"  ‚Üí Ensure the model '{self.model_name}' is available in the backend pool\\n\"\n",
    "                        f\"  ‚Üí Endpoint: {self.llm_endpoint}\"\n",
    "                    )\n",
    "                    utils.print_error(error_msg)\n",
    "                    # Remove the user message that failed so conversation stays consistent\n",
    "                    self.messages.pop()\n",
    "                    return f\"[ERROR] {error_msg}\"\n",
    "    \n",
    "    def get_metrics(self) -> dict:\n",
    "        \"\"\"Return token usage metrics including retries.\"\"\"\n",
    "        return {\n",
    "            \"total_tokens\": self.total_tokens,\n",
    "            \"prompt_tokens\": self.prompt_tokens,\n",
    "            \"completion_tokens\": self.completion_tokens,\n",
    "            \"calls\": self.calls,\n",
    "            \"retries\": self.retries\n",
    "        }\n",
    "\n",
    "utils.print_ok(\"LangChain Support Agent class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92df338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LangChain Support Agent with local configuration\n",
    "if \"Support-Bot\" in contract_keys:\n",
    "    support_key = contract_keys[\"Support-Bot\"][\"key\"]\n",
    "    \n",
    "    utils.print_info(\"ü¶ú Starting LangChain Support Agent conversation...\")\n",
    "    utils.print_info(\"=\"*60)\n",
    "    utils.print_info(f\"üì¶ Using local configuration with APIM endpoint\")\n",
    "    \n",
    "    try:\n",
    "        support_agent = LangChainSupportAgent(\n",
    "            llm_endpoint=chat_completions_url,  # Local endpoint variable\n",
    "            api_key=support_key,                 # Local API key variable\n",
    "            model_name=model_name                # Model name in body\n",
    "        )\n",
    "        \n",
    "        # Simulate a support conversation\n",
    "        support_conversation = [\n",
    "            \"Hi, I'm having trouble connecting to the VPN. It keeps timing out.\",\n",
    "            \"I'm using Windows 11 and the company VPN client version 3.2.\",\n",
    "            \"I've tried restarting but the issue persists. What else can I try?\",\n",
    "            \"The network adapter shows it's connected but no internet access through VPN.\",\n",
    "            \"That worked! The DNS settings were incorrect. Thank you for your help!\"\n",
    "        ]\n",
    "        \n",
    "        for i, user_msg in enumerate(support_conversation, 1):\n",
    "            print(f\"\\nüë§ User ({i}/{len(support_conversation)}): {user_msg}\")\n",
    "            response = support_agent.chat(user_msg)\n",
    "            print(f\"ü§ñ Support Agent: {response[:300]}{'...' if len(response) > 300 else ''}\")\n",
    "            time.sleep(1)  # Rate limiting\n",
    "        \n",
    "        # Store metrics\n",
    "        agent_metrics[\"LangChain (Support)\"] = support_agent.get_metrics()\n",
    "        utils.print_ok(f\"\\nüìä Support Agent Metrics: {agent_metrics['LangChain (Support)']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        utils.print_error(f\"Failed to initialize Support Agent: {e}\")\n",
    "else:\n",
    "    utils.print_warning(\"Support-Bot contract not found. Skipping LangChain test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b7d8b",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Agent Performance Comparison\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e060de2",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "### 7Ô∏è‚É£ Display Agent Statistics and Comparison\n",
    "\n",
    "Visualize token consumption across all agent frameworks using pie charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter agents with data\n",
    "active_agents = {k: v for k, v in agent_metrics.items() if v.get('total_tokens', 0) > 0}\n",
    "\n",
    "if active_agents:\n",
    "    # Print summary table\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"üìä AGENT FRAMEWORKS PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*90)\n",
    "    print(f\"{'Agent Framework':<30} {'Calls':<8} {'Retries':<10} {'Prompt':<12} {'Completion':<12} {'Total':<12}\")\n",
    "    print(\"-\"*90)\n",
    "    \n",
    "    total_all_tokens = 0\n",
    "    total_all_retries = 0\n",
    "    for agent_name, metrics in active_agents.items():\n",
    "        retries = metrics.get('retries', 0)\n",
    "        print(f\"{agent_name:<30} {metrics['calls']:<8} {retries:<10} {metrics['prompt_tokens']:<12} {metrics['completion_tokens']:<12} {metrics['total_tokens']:<12}\")\n",
    "        total_all_tokens += metrics['total_tokens']\n",
    "        total_all_retries += retries\n",
    "    \n",
    "    print(\"-\"*90)\n",
    "    print(f\"{'TOTAL':<30} {'':<8} {total_all_retries:<10} {'':<12} {'':<12} {total_all_tokens:<12}\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    # Color scheme\n",
    "    colors = ['#2E86AB', '#A23B72', '#F18F01']\n",
    "    \n",
    "    # 1. Total Tokens Pie Chart\n",
    "    labels = list(active_agents.keys())\n",
    "    total_tokens = [m['total_tokens'] for m in active_agents.values()]\n",
    "    \n",
    "    axes[0].pie(total_tokens, labels=labels, autopct='%1.1f%%', colors=colors[:len(labels)], \n",
    "                startangle=90, explode=[0.02]*len(labels))\n",
    "    axes[0].set_title('Total Tokens by Agent', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 2. Prompt vs Completion Tokens (Stacked Bar)\n",
    "    x = np.arange(len(labels))\n",
    "    prompt_tokens = [m['prompt_tokens'] for m in active_agents.values()]\n",
    "    completion_tokens = [m['completion_tokens'] for m in active_agents.values()]\n",
    "    \n",
    "    axes[1].bar(x, prompt_tokens, label='Prompt Tokens', color='#2E86AB', alpha=0.8)\n",
    "    axes[1].bar(x, completion_tokens, bottom=prompt_tokens, label='Completion Tokens', color='#F18F01', alpha=0.8)\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels([l.split('(')[0].strip() for l in labels], rotation=15, ha='right')\n",
    "    axes[1].set_ylabel('Tokens')\n",
    "    axes[1].set_title('Token Distribution by Agent', fontsize=12, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # 3. API Calls vs Retries (Grouped Bar)\n",
    "    calls = [m['calls'] for m in active_agents.values()]\n",
    "    retries = [m.get('retries', 0) for m in active_agents.values()]\n",
    "    \n",
    "    bar_width = 0.35\n",
    "    axes[2].bar(x - bar_width/2, calls, bar_width, label='Successful Calls', color='#2E86AB', alpha=0.8)\n",
    "    axes[2].bar(x + bar_width/2, retries, bar_width, label='Retries', color='#E84855', alpha=0.8)\n",
    "    axes[2].set_xticks(x)\n",
    "    axes[2].set_xticklabels([l.split('(')[0].strip() for l in labels], rotation=15, ha='right')\n",
    "    axes[2].set_ylabel('Count')\n",
    "    axes[2].set_title('Calls vs Retries by Agent', fontsize=12, fontweight='bold')\n",
    "    axes[2].legend()\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (call, retry) in enumerate(zip(calls, retries)):\n",
    "        axes[2].text(i - bar_width/2, call + 0.1, str(call), ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "        if retry > 0:\n",
    "            axes[2].text(i + bar_width/2, retry + 0.1, str(retry), ha='center', va='bottom', fontweight='bold', fontsize=9, color='#E84855')\n",
    "    \n",
    "    # 4. Retry Rate (% of total attempts that were retries)\n",
    "    retry_rates = []\n",
    "    for m in active_agents.values():\n",
    "        total_attempts = m['calls'] + m.get('retries', 0)\n",
    "        rate = (m.get('retries', 0) / total_attempts * 100) if total_attempts > 0 else 0\n",
    "        retry_rates.append(rate)\n",
    "    \n",
    "    bar_colors = ['#4CAF50' if r == 0 else '#FF9800' if r < 30 else '#E84855' for r in retry_rates]\n",
    "    bars = axes[3].bar(x, retry_rates, color=bar_colors, alpha=0.8)\n",
    "    axes[3].set_xticks(x)\n",
    "    axes[3].set_xticklabels([l.split('(')[0].strip() for l in labels], rotation=15, ha='right')\n",
    "    axes[3].set_ylabel('Retry Rate (%)')\n",
    "    axes[3].set_title('Retry Rate by Agent', fontsize=12, fontweight='bold')\n",
    "    axes[3].set_ylim(0, max(max(retry_rates) * 1.3, 10))\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, rate in zip(bars, retry_rates):\n",
    "        axes[3].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "                     f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('agent_metrics_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    utils.print_ok(\"Visualization saved to 'agent_metrics_comparison.png'\")\n",
    "else:\n",
    "    utils.print_warning(\"No agent metrics available. Run the agent tests first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd8e3e",
   "metadata": {},
   "source": [
    "<a id='8'></a>\n",
    "### 8Ô∏è‚É£ Token Efficiency Analysis\n",
    "\n",
    "Analyze the token efficiency (completion tokens per call) for each agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "active_agents = {k: v for k, v in agent_metrics.items() if v.get('total_tokens', 0) > 0}\n",
    "\n",
    "if active_agents:\n",
    "    # Calculate efficiency metrics\n",
    "    efficiency_data = []\n",
    "    for agent_name, metrics in active_agents.items():\n",
    "        calls = metrics['calls']\n",
    "        retries = metrics.get('retries', 0)\n",
    "        if calls > 0:\n",
    "            avg_total = metrics['total_tokens'] / calls\n",
    "            avg_prompt = metrics['prompt_tokens'] / calls\n",
    "            avg_completion = metrics['completion_tokens'] / calls\n",
    "            efficiency = metrics['completion_tokens'] / metrics['total_tokens'] * 100 if metrics['total_tokens'] > 0 else 0\n",
    "            total_attempts = calls + retries\n",
    "            reliability = (calls / total_attempts * 100) if total_attempts > 0 else 100.0\n",
    "            \n",
    "            efficiency_data.append({\n",
    "                'name': agent_name,\n",
    "                'avg_total': avg_total,\n",
    "                'avg_prompt': avg_prompt,\n",
    "                'avg_completion': avg_completion,\n",
    "                'efficiency': efficiency,\n",
    "                'retries': retries,\n",
    "                'reliability': reliability\n",
    "            })\n",
    "    \n",
    "    # Print efficiency table\n",
    "    print(\"\\n\" + \"=\"*95)\n",
    "    print(\"üìà TOKEN EFFICIENCY & RELIABILITY ANALYSIS\")\n",
    "    print(\"=\"*95)\n",
    "    print(f\"{'Agent Framework':<30} {'Avg Total':<12} {'Avg Prompt':<12} {'Avg Compl.':<12} {'Efficiency':<12} {'Retries':<10} {'Reliability':<12}\")\n",
    "    print(\"-\"*95)\n",
    "    \n",
    "    for data in efficiency_data:\n",
    "        print(f\"{data['name']:<30} {data['avg_total']:<12.1f} {data['avg_prompt']:<12.1f} {data['avg_completion']:<12.1f} {data['efficiency']:<11.1f}% {data['retries']:<10} {data['reliability']:<11.1f}%\")\n",
    "    \n",
    "    print(\"=\"*95)\n",
    "    print(\"\\nüí° Efficiency = (Completion Tokens / Total Tokens) √ó 100\")\n",
    "    print(\"   Higher efficiency means more output for less input (context)\")\n",
    "    print(\"üîÑ Reliability = (Successful Calls / Total Attempts) √ó 100\")\n",
    "    print(\"   Higher reliability means fewer retries needed\")\n",
    "    \n",
    "    # Create side-by-side visualization: Efficiency vs Reliability\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    labels = [d['name'].split('(')[0].strip() for d in efficiency_data]\n",
    "    efficiencies = [d['efficiency'] for d in efficiency_data]\n",
    "    reliabilities = [d['reliability'] for d in efficiency_data]\n",
    "    retries_list = [d['retries'] for d in efficiency_data]\n",
    "    colors = ['#2E86AB', '#A23B72', '#F18F01']\n",
    "    \n",
    "    # Left: Token Efficiency\n",
    "    bars1 = ax1.barh(labels, efficiencies, color=colors[:len(labels)], alpha=0.8)\n",
    "    for bar, eff in zip(bars1, efficiencies):\n",
    "        ax1.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                f'{eff:.1f}%', va='center', fontweight='bold')\n",
    "    ax1.set_xlabel('Efficiency (%)')\n",
    "    ax1.set_title('Token Efficiency by Agent', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlim(0, max(efficiencies) * 1.2)\n",
    "    \n",
    "    # Right: Reliability (with retry count annotation)\n",
    "    reliability_colors = ['#4CAF50' if r == 100 else '#FF9800' if r > 80 else '#E84855' for r in reliabilities]\n",
    "    bars2 = ax2.barh(labels, reliabilities, color=reliability_colors, alpha=0.8)\n",
    "    for bar, rel, retries in zip(bars2, reliabilities, retries_list):\n",
    "        label = f'{rel:.1f}%'\n",
    "        if retries > 0:\n",
    "            label += f' ({retries} retries)'\n",
    "        ax2.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                label, va='center', fontweight='bold')\n",
    "    ax2.set_xlabel('Reliability (%)')\n",
    "    ax2.set_title('Call Reliability by Agent', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlim(0, 120)\n",
    "    ax2.axvline(x=100, color='#4CAF50', linestyle='--', alpha=0.3, label='Perfect reliability')\n",
    "    ax2.legend(loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    utils.print_warning(\"No agent metrics available for efficiency analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb748120",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### üìã Summary\n",
    "\n",
    "This notebook tested the following access contracts with different agent frameworks:\n",
    "\n",
    "| Access Contract | Agent Framework | Use Case | Integration |\n",
    "|----------------|-----------------|----------|-------------|\n",
    "| Sales-Assistant | Microsoft Agent Framework | Sales inquiries & pricing | Azure Key Vault (endpoint + key) |\n",
    "| HR-ChatAgent | Microsoft Foundry Agent SDK | HR policies & benefits | Foundry Project Connection |\n",
    "| Support-Bot | LangChain | Technical support | Local (direct endpoint + key) |\n",
    "\n",
    "Each agent simulated a multi-turn conversation relevant to its business domain.\n",
    "The metrics collected help compare token consumption across different frameworks.\n",
    "\n",
    "**Integration Patterns:**\n",
    "- **Microsoft Agent Framework (Sales)**: Retrieves endpoint and API key from Azure Key Vault secrets, uses `AzureOpenAIChatClient.as_agent()`\n",
    "- **Foundry SDK (HR)**: Uses `connection_name/model_name` deployment pattern via Foundry project\n",
    "- **LangChain (Support)**: Local configuration with endpoint, key, and model in request body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce719c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "utils.print_info(\"\\n\" + \"=\"*60)\n",
    "utils.print_info(\"üéâ AGENT FRAMEWORKS TESTING COMPLETE!\")\n",
    "utils.print_info(\"=\"*60)\n",
    "\n",
    "total_retries = 0\n",
    "for agent_name, metrics in agent_metrics.items():\n",
    "    retries = metrics.get('retries', 0)\n",
    "    total_retries += retries\n",
    "    if metrics.get('total_tokens', 0) > 0:\n",
    "        retry_info = f\", {retries} retries\" if retries > 0 else \"\"\n",
    "        utils.print_ok(f\"‚úÖ {agent_name}: {metrics['total_tokens']} total tokens, {metrics['calls']} calls{retry_info}\")\n",
    "    else:\n",
    "        utils.print_warning(f\"‚ö†Ô∏è {agent_name}: No data (contract may not be deployed)\")\n",
    "\n",
    "if total_retries > 0:\n",
    "    utils.print_warning(f\"\\nüîÑ Total retries across all agents: {total_retries}\")\n",
    "    utils.print_info(\"  Consider reviewing rate limits or backend pool capacity if retries are high\")\n",
    "\n",
    "utils.print_info(\"\\nüìå Next Steps:\")\n",
    "utils.print_info(\"  1. Review token consumption patterns and retry rates\")\n",
    "utils.print_info(\"  2. Adjust rate limits in access contracts if retries are frequent\")\n",
    "utils.print_info(\"  3. Implement production-ready error handling\")\n",
    "utils.print_info(\"  4. Add monitoring and alerting for each agent type\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
